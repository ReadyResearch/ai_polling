# **AIPI Harris Survey**

Online sample of 1080 respondents fielded over web panels on August 11 and weighted to
education, gender, race, survey engagement, and 2020 election results. The margin of error
is +/- 3.7.

**1) The US AI Safety Institute, housed within the National Institute of Standards and Technology (NIST),**

**is a government initiative aimed at advancing the science and practice of AI safety to ensure the**

**responsible development and use of artificial intelligence. Its mission is to evaluate AI capabilities and**

**risks, develop safety guidelines, and foster collaboration among diverse communities to maximize AI's**

**benefits while mitigating potential harms to national security, public safety, and individual rights. The**

**US national AI Safety Institute creates voluntary safety standards for companies developing powerful**

**AI models.**

**Some policy makers are considering giving this institution legislative authorization through legislation,**

**meaning it would remain as a stable institution regardless of administration. Would you support or**

**oppose authorizing this agency through legislation?**

All D I R

Support authorizing the AI safety institute ................................... 54 61 54 47

Oppose authorizing the AI safety institute ................................... 16 12 10 23

Not sure............................................................................................. 30 27 36 30

**2) The US national AI Safety Institute creates voluntary safety standards for companies developing**

**powerful AI models.**

**Some policy makers have introduced a bill that authorizes the US national AI Safety Institute as a**

**stable institution. The bill also establishes testing facilities at government labs, sets up prize**

**competitions for AI breakthroughs, makes datasets available for research, and promotes international**

**collaboration on AI standards and research.**

**Do you support or oppose this bill?**

All D I R

Support this bill ................................................................................ 53 59 54 47

Oppose this bill................................................................................. 18 12 15 25

Not sure............................................................................................. 29 29 31 28

**3) Which approach to AI regulation would you prefer?**

**Ban:**

**Under this approach, building AI systems larger than those currently in existence would be made**

**illegal for the time being. More powerful systems would only be allowed to be built after more**

**research has been conducted to prove that these more powerful models would be safe.**

**No regulation:**

**Under this approach, AI systems themselves would not be subject to regulatory requirements. All**

**regulation would fall on users of foundation AI models, who would be responsible for how to use**

**models for illegal activity. Producers of the models would not face additional regulation.**

All D I R

Ban ..................................................................................................... 46 48 41 46

No regulation.................................................................................... 18 17 15 22

Not sure............................................................................................. 36 34 44 32

**4) Which approach to AI regulation would you prefer?**

**Ban:**

**Under this approach, building AI systems larger than those currently in existence would be made**

**illegal for the time being. More powerful systems would only be allowed to be built after more**

**research has been conducted to prove that these more powerful models would be safe.**

**Safety mandates:**

**Under this approach, companies developing advanced AI systems would be mandated to implement**

**safety measures and security standards for their most advanced models. They could only release the**

**model once a government oversight board certifies they have properly accounted for extreme risks,**

**including preventing AI from being used to create bioweapons and launch cyberattacks.**

All D I R

Ban ..................................................................................................... 20 22 17 22

Safety mandates............................................................................... 59 60 60 57

Not sure............................................................................................. 20 18 23 21

**5) Which approach to AI regulation would you prefer?**

**No regulation:**

**Under this approach, AI systems themselves would not be subject to regulatory requirements. All**

**regulation would fall on users of foundation AI models, who would be responsible for how to use**

**models for illegal activity. Producers of the models would not face additional regulation.**

**Safety mandates:**

**Under this approach, companies developing advanced AI systems would be mandated to implement**

**safety measures and security standards for their most advanced models. They could only release the**

**model once a government oversight board certifies they have properly accounted for extreme risks,**

**including preventing AI from being used to create bioweapons and launch cyberattacks.**

All D I R

No regulation.................................................................................... 7 4 6 10

Safety mandates............................................................................... 76 78 76 74

Not sure............................................................................................. 17 18 18 17

**6) Kamala Harris and allies have expressed many ideas around AI. Kamala Harris has said**
**that AI offers both great promise and great risks.**

**If Kamala becomes president in 2025, what should she prioritize?**

All D I R

Realizing the promise of AI ............................................................. 22 27 16 21

Minimizing the risks of AI ................................................................ 53 53 51 53

Not sure............................................................................................. 25 20 33 25

**7) Kamala Harris and allies have expressed many ideas around AI. Kamala Harris has**
**discussed numerous risks that should be prioritized.**

**If Kamala becomes president in 2025, which set of risks should she prioritize?**

All D I R

Reducing the risk of bias and misinformation caused by AI....... 23 29 23 18

Reducing the risk of cyberattacks and biological attacks
caused by AI...................................................................................... 55 55 49 58

Not sure............................................................................................. 22 16 28 24

**8) Kamala Harris and allies have expressed many ideas around AI. Kamala Harris' circle have**

**discussed both the need to reduce risks from AI accidents and misuse and the need to**

**democratize the technology and prevent its concentration among a few companies.**

**If Kamala becomes president in 2025, which should she prioritize?**

All D I R

Reducing the risks of AI accidents and misuse............................. 55 60 53 52

Preventing AI from being in the hands of just a few companies 25 25 22 27

Not sure............................................................................................. 20 15 25 22

**9) Kamala Harris and allies have expressed many ideas around AI. During Biden's term in office,**

**Kamala Harris helped garner voluntary commitments from AI companies on AI safety testing, securing**

**their AI models, and sharing information about risks from their models.**

**There is a debate over whether these commitments should be made mandatory rather than voluntary**

**under a Harris administration.**

**Those favoring voluntary commitments say that an overbearing regulatory state would create red**

**tape and stand in the way of innovation. They say that AI companies are currently following through**

**with their commitments, providing the best of both worlds.**

**Those favoring mandatory commitments say that the only way we can be sure that models are safe is**

**with mandatory commitments. They say that AI companies have been uneven in their cooperation**

**thus far, and can't be trusted as competition intensifies.**

**If Kamala becomes president in 2025, do you think she should push for mandatory commitments?**

All D I R

Yes, a Harris administration should try to make commitments
mandatory......................................................................................... 55 73 51 40

No, a Harris administration should maintain voluntary
commitments.................................................................................... 18 10 13 28

Not sure............................................................................................. 28 18 36 31

**10) Preference for Kamala Harris Quotes**

All D I R

When a woman is threatened by an abusive partner with
explicit deepfake photographs, is that not existential for her?
When a young father is wrongfully imprisoned because of
bias? Is that not existential for his family? .................................... 34 36 35 31

AI has the potential to do profound good to develop powerful
new medicines to treat and even cure the diseases that have
for generations plagued humanity, to dramatically improve
agricultural production to help address global food insecurity,
and to save countless lives in the fight against the climate
crisis. .................................................................................................. 43 43 44 42

The benefits of AI must be shared equally, and we must
address predictable threats, including deep fakes, data
privacy violations, and algorithmic discrimination. ..................... 50 50 49 50

AI has the potential to cause profound harm, from AI-enabled
cyberattacks at a scale beyond anything we have seen before
to AI-formulated bio-weapons that could endanger the lives of
millions .............................................................................................. 53 50 51 57

The international community should consider and address
the full spectrum of AI risk threats to humanity as a whole as
well as threats to individuals, communities, to our institutions,
and to our most vulnerable populations. ..................................... 57 57 55 58

I believe that all leaders from government, civil society and
the private sector have a moral, ethical and societal duty to
make sure that artificial intelligence is adopted and advanced
in a way that protects the public from potential harm, while
ensuring everyone is able to enjoy its full benefit. ...................... 63 63 66 60


