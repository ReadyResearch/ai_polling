Question_Text,Response_Scale,Category,Agreement,Neutral,Disagreement,N_Respondents,Country,Survey_Organisation,Fieldwork_Date,Notes
How much would you support/oppose pausing the development of large-scale Al systems for at least 6 months worldwide?,"Strongly support, Support, Slightly support, Neither support nor oppose, Slightly oppose, Oppose, Strongly oppose, Don't know / no opinion",AI_Regulation,51.0,20.0,25.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Strongly support', 'Support', and 'Slightly support'. Disagreement combines 'Slightly oppose', 'Oppose', and 'Strongly oppose'. 'Don't know / no opinion' was 4% and is not included in the Neutral percentage."
Do you think Al should be regulated by a federal agency (similarly to how the FDA regulates the approval of drugs and medical devices)?,"Yes, Lean yes, Lean no, No, Don't know / No opinion",AI_Regulation,70.0,9.0,22.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Yes' and 'Lean yes'. Disagreement combines 'Lean no' and 'No'. Neutral is 'Don't know / No opinion'."
"In your daily life, how much do you worry about the negative effects Al could have on your life or on society more broadly?","Nearly all the time, A lot, A fair amount, Only a little bit, Not at all",AI_Risk_Concern,29.0,0.0,71.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Nearly all the time', 'A lot', and 'A fair amount' (representing 'worrying a fair amount or more'). Disagreement combines 'Only a little bit' and 'Not at all' (representing 'worrying only a little bit or not at all'). There was no explicit neutral option."
How likely do you think Al is to cause the end of the human race within the next 10 years?,"Extremely likely, Highly likely, Moderately likely, Only slightly likely, Not at all likely, Don't know / No opinion",Extinction_Risk,9.0,3.0,88.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Extremely likely', 'Highly likely', and 'Moderately likely'. Disagreement combines 'Only slightly likely' and 'Not at all likely'. Neutral is 'Don't know / No opinion'."
How likely do you think Al is to cause the end of the human race within the next 50 years?,"Extremely likely, Highly likely, Moderately likely, Only slightly likely, Not at all likely, Don't know / No opinion",Extinction_Risk,22.0,3.0,75.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Extremely likely', 'Highly likely', and 'Moderately likely'. Disagreement combines 'Only slightly likely' and 'Not at all likely'. Neutral is 'Don't know / No opinion'."
How likely do you think it is that Al will eventually become more intelligent than people?,"It already is more intelligent than people, Extremely likely, Highly likely, Moderately likely, Only slightly likely, Not at all likely, Don't know / No opinion",Other,66.0,4.0,30.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'It already is more intelligent than people', 'Extremely likely', 'Highly likely', and 'Moderately likely'. Disagreement combines 'Only slightly likely' and 'Not at all likely'. Neutral is 'Don't know / No opinion'."
Do you think Al will do more harm than good?,"Do much more good than harm, Do more good than harm, Do slightly more good than harm, Neutral, Do slightly more harm than good, Do more harm than good, Do much more harm than good, Don't know / No opinion",AI_Sentiment,48.0,19.0,30.0,2444,US,Rethink Priorities,2023-04-14,"Online poll, poststratified to be representative of the US population. Conducted via Prolific participant pool. Agreement combines 'Do much more good than harm', 'Do more good than harm', and 'Do slightly more good than harm'. Disagreement combines 'Do slightly more harm than good', 'Do more harm than good', and 'Do much more harm than good'. 'Neutral' is a distinct response option. 'Don't know / No opinion' was 2% and is not included in the Neutral percentage."
How likely or unlikely do you think it is that a human extinction event will strike in your lifetime?,"Very likely, Somewhat likely, Somewhat unlikely, Very unlikely, Don't know",Extinction_Risk,11.0,0.0,77.0,2076,GB,YouGov,2023-05-31,Sample size is 2076 adults in GB.
"If a human extinction event were to occur, do you think it is more likely to be a result of **technology** (e.g. artificial intelligence or nuclear weaponry), or an **environmental cause** (e.g. climate change or an asteroid)?","Technology, An environmental cause, Don't know",AI_Risk_Concern,34.0,21.0,44.0,2076,GB,YouGov,2023-05-31,Sample size is 2076 adults in GB.
Do you think the government should or should not be developing realistic contingency plans for Robots / artificial intelligence?,"Should be developing a contingency plan, Should **not** be developing a contingency plan, Don't know",AI_Regulation,44.0,21.0,35.0,2076,GB,YouGov,2023-05-31,Sample size is 2076 adults in GB.
"Do you agree or disagree that 'Overall, artificial intelligence (AI) creates more problems than it solves?'","Agree, Disagree",AI_Sentiment,57.0,0.0,43.0,1481,Australia,Roy Morgan Snap SMS Survey,2023-08-09,"Australians 16+, Weighted results. Conducted in conjunction with the Campaign for AI Safety."
Do you believe artificial intelligence (AI) presents a risk of human extinction in the next two decades?,"Yes, No",Extinction_Risk,20.0,0.0,80.0,1481,Australia,Roy Morgan Snap SMS Survey,2023-08-09,"Australians 16+, Weighted results. Conducted in conjunction with the Campaign for AI Safety."
Some policy makers are suggesting that the Trump administration should make it easier to build infrastructure for large AI models. What do you think?,The Trump administration should make it easier to build infrastructure for large AI models no matter what (6%); The Trump administration should make it easier to build infrastructure for large AI models if this is paired with mandatory safety testing (39%); The Trump administration shouldn't make it easier to build infrastructure for large AI models no matter what (27%); Not sure (29%).,AI_Regulation,45.0,29.0,27.0,1084,United States,AI PI,,"Online sample of 1084 respondents fielded over web panels and weighted to education, age, gender, race, and 2020 election results. The margin of error is +/- 4.6."
Should Elon Musk devote much of his time working with the Trump administration to making sure US AI policy is sensible?,Yes (51%); No (29%); Not sure (20%).,AI_Regulation,51.0,20.0,29.0,1084,United States,AI PI,,"Online sample of 1084 respondents fielded over web panels and weighted to education, age, gender, race, and 2020 election results. The margin of error is +/- 4.6."
"Donald Trump has discussed how powerful AI systems will require extensive power, power that may be difficult to generate because of current regulations on power-plant construction. Do you think regulation should be eased so the power needed for AI systems can be built?","Yes, regulations should be eased on power generation for AI systems (31%); No, regulations should not be eased on power generation for AI systems (48%); Not sure (21%).",AI_Regulation,31.0,21.0,48.0,1084,United States,AI PI,,"Online sample of 1084 respondents fielded over web panels and weighted to education, age, gender, race, and 2020 election results. The margin of error is +/- 4.6."
"TM3145Y23_3. [The increased use of Artificial Intelligence (AI)] How concerned are you, if at all, with the following","Very concerned, Somewhat concerned, Not very concerned, Not at all concerned, Not sure",AI_Risk_Concern,68.0,7.0,25.0,4415,US,Ipsos/Reuters Poll,2023-05-09,"Conducted online. Sample of 4,415 adults age 18+ from the continental U.S., Alaska, and Hawaii. Credibility interval of +/- 1.8 percentage points for all respondents. Posthoc weights applied."
TM3144Y23_1. [Artificial intelligence (AI) will have unpredictable consequences that people will ultimately not be able to control] Please indicate how much you agree or disagree with the following statements.,"Strongly agree, Somewhat agree, Somewhat disagree, Strongly disagree, Don't know",AI_Risk_Concern,67.0,16.0,18.0,4415,US,Ipsos/Reuters Poll,2023-05-09,"Conducted online. Sample of 4,415 adults age 18+ from the continental U.S., Alaska, and Hawaii. Credibility interval of +/- 1.8 percentage points for all respondents. Posthoc weights applied."
TM3144Y23_2. [Artificial intelligence (AI) is bad for humanity] Please indicate how much you agree or disagree with the following statements.,"Strongly agree, Somewhat agree, Somewhat disagree, Strongly disagree, Don't know",AI_Risk_Concern,51.0,19.0,29.0,4415,US,Ipsos/Reuters Poll,2023-05-09,"Conducted online. Sample of 4,415 adults age 18+ from the continental U.S., Alaska, and Hawaii. Credibility interval of +/- 1.8 percentage points for all respondents. Posthoc weights applied."
TM3144Y23_3. [The uncontrollable effects of artificial intelligence (AI) could be so harmful that it may risk the future of humankind] Please indicate how much you agree or disagree with the following statements.,"Strongly agree, Somewhat agree, Somewhat disagree, Strongly disagree, Don't know",Extinction_Risk,61.0,17.0,22.0,4415,US,Ipsos/Reuters Poll,2023-05-09,"Conducted online. Sample of 4,415 adults age 18+ from the continental U.S., Alaska, and Hawaii. Credibility interval of +/- 1.8 percentage points for all respondents. Posthoc weights applied."
TM3144Y23_4. [Companies that replace workers with artificial intelligence (AI) should pay a financial penalty to offset the increased unemployment] Please indicate how much you agree or disagree with the following statements.,"Strongly agree, Somewhat agree, Somewhat disagree, Strongly disagree, Don't know",Job_Displacement,63.0,17.0,20.0,4415,US,Ipsos/Reuters Poll,2023-05-09,"Conducted online. Sample of 4,415 adults age 18+ from the continental U.S., Alaska, and Hawaii. Credibility interval of +/- 1.8 percentage points for all respondents. Posthoc weights applied."
"The US AI Safety Institute, housed within the National Institute of Standards and Technology (NIST), is a government initiative aimed at advancing the science and practice of Al safety to ensure the responsible development and use of artificial intelligence. Its mission is to evaluate Al capabilities and risks, develop safety guidelines, and foster collaboration among diverse communities to maximize Al's benefits while mitigating potential harms to national security, public safety, and individual rights. The US national Al Safety Institute creates voluntary safety standards for companies developing powerful Al models. Some policy makers are considering giving this institution legislative authorization through legislation, meaning it would remain as a stable institution regardless of administration. Would you support or oppose authorizing this agency through legislation?","Support authorizing the AI safety institute, Oppose authorizing the AI safety institute, Not sure",AI_Regulation,54.0,30.0,16.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"The US national AI Safety Institute creates voluntary safety standards for companies developing powerful AI models. Some policy makers have introduced a bill that authorizes the US national AI Safety Institute as a stable institution. The bill also establishes testing facilities at government labs, sets up prize competitions for AI breakthroughs, makes datasets available for research, and promotes international collaboration on AI standards and research. Do you support or oppose this bill?","Support this bill, Oppose this bill, Not sure",AI_Regulation,53.0,29.0,18.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Which approach to AI regulation would you prefer? Ban: Under this approach, building AI systems larger than those currently in existence would be made illegal for the time being. More powerful systems would only be allowed to be built after more research has been conducted to prove that these more powerful models would be safe. No regulation: Under this approach, AI systems themselves would not be subject to regulatory requirements. All regulation would fall on users of foundation AI models, who would be responsible for how to use models for illegal activity. Producers of the models would not face additional regulation.","Ban, No regulation, Not sure",AI_Regulation,46.0,36.0,18.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Which approach to AI regulation would you prefer? Ban: Under this approach, building AI systems larger than those currently in existence would be made illegal for the time being. More powerful systems would only be allowed to be built after more research has been conducted to prove that these more powerful models would be safe. Safety mandates: Under this approach, companies developing advanced AI systems would be mandated to implement safety measures and security standards for their most advanced models. They could only release the model once a government oversight board certifies they have properly accounted for extreme risks, including preventing AI from being used to create bioweapons and launch cyberattacks.","Ban, Safety mandates, Not sure",AI_Regulation,59.0,20.0,20.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Which approach to AI regulation would you prefer? No regulation: Under this approach, AI systems themselves would not be subject to regulatory requirements. All regulation would fall on users of foundation AI models, who would be responsible for how to use models for illegal activity. Producers of the models would not face additional regulation. Safety mandates: Under this approach, companies developing advanced AI systems would be mandated to implement safety measures and security standards for their most advanced models. They could only release the model once a government oversight board certifies they have properly accounted for extreme risks, including preventing AI from being used to create bioweapons and launch cyberattacks.","No regulation, Safety mandates, Not sure",AI_Regulation,76.0,17.0,7.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Kamala Harris and allies have expressed many ideas around AI. Kamala Harris has said that AI offers both great promise and great risks. If Kamala becomes president in 2025, what should she prioritize?","Realizing the promise of AI, Minimizing the risks of AI, Not sure",AI_Sentiment,53.0,25.0,22.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Kamala Harris and allies have expressed many ideas around AI. Kamala Harris has discussed numerous risks that should be prioritized. If Kamala becomes president in 2025, which set of risks should she prioritize?","Reducing the risk of bias and misinformation caused by AI, Reducing the risk of cyberattacks and biological attacks caused by AI, Not sure",AI_Risk_Concern,55.0,22.0,23.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Kamala Harris and allies have expressed many ideas around AI. Kamala Harris' circle have discussed both the need to reduce risks from AI accidents and misuse and the need to democratize the technology and prevent its concentration among a few companies. If Kamala becomes president in 2025, which should she prioritize?","Reducing the risks of AI accidents and misuse, Preventing AI from being in the hands of just a few companies, Not sure",AI_Risk_Concern,55.0,20.0,25.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"Kamala Harris and allies have expressed many ideas around AI. During Biden's term in office, Kamala Harris helped garner voluntary commitments from AI companies on AI safety testing, securing their AI models, and sharing information about risks from their models. There is a debate over whether these commitments should be made mandatory rather than voluntary under a Harris administration. Those favoring voluntary commitments say that an overbearing regulatory state would create red tape and stand in the way of innovation. They say that AI companies are currently following through with their commitments, providing the best of both worlds. Those favoring mandatory commitments say that the only way we can be sure that models are safe is with mandatory commitments. They say that AI companies have been uneven in their cooperation thus far, and can't be trusted as competition intensifies. If Kamala becomes president in 2025, do you think she should push for mandatory commitments?","Yes, a Harris administration should try to make commitments mandatory, No, a Harris administration should maintain voluntary commitments, Not sure",AI_Regulation,55.0,28.0,18.0,1080,United States,AIPI Harris Survey,,"Online sample of 1080 respondents fielded over web panels on August 11. Weighted to education, gender, race, survey engagement, and 2020 election results. Margin of error is +/- 3.7. Year of fieldwork not specified, but context suggests 2023 or 2024."
"In your opinion, does artificial intelligence...","Do more good than harm, Do more harm than good, Do equal amounts of harm and good",AI_Sentiment,13.0,56.0,31.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents 'Do more good than harm'. 'Neutral' represents 'Do equal amounts of harm and good'. 'Disagreement' represents 'Do more harm than good'.
"In your opinion, what type of effect will artificial intelligence have on the total number of jobs in the United States over the next 10 years?","Increase the total number of jobs, Have no impact on the total number of jobs, Reduce the total number of jobs",Job_Displacement,6.0,19.0,75.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents 'Increase the total number of jobs'. 'Neutral' represents 'Have no impact on the total number of jobs'. 'Disagreement' represents 'Reduce the total number of jobs'.
"In general, how much do you trust businesses to use artificial intelligence responsibly?","A lot, Some, Not much, Not at all",AI_Regulation,21.0,0.0,77.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' combines 'A lot' (2%) and 'Some' (19%). 'Disagreement' combines 'Not much' (44%) and 'Not at all' (33%). Neutral is not explicitly provided in the combined percentages.
How concerned are you about artificial intelligence being used in the following areas? Recommending which employees a company should hire,"Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,85.0,0.0,15.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
How concerned are you about artificial intelligence being used in the following areas? Driving a car,"Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,83.0,0.0,17.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
How concerned are you about artificial intelligence being used in the following areas? Recommending medical advice,"Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,80.0,0.0,20.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
How concerned are you about artificial intelligence being used in the following areas? Recommending financial advice,"Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,71.0,0.0,29.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
"How concerned are you about artificial intelligence being used in the following areas? Creating original artistic content such as pictures, videos, literature or scripts","Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,71.0,0.0,29.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
How concerned are you about artificial intelligence being used in the following areas? Assisting students with homework or studying,"Extremely concerned, Somewhat concerned, Not very concerned, Not at all concerned",AI_Risk_Concern,66.0,0.0,34.0,5835,USA,Bentley-Gallup,,Results for 2024. 'Agreement' represents '% Extremely + Somewhat concerned'. 'Disagreement' is calculated as 100% - Agreement.
