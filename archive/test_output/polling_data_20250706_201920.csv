question_text,category,survey_organisation,country,fieldwork_date,agreement,neutral,disagreement,n_respondents,response_scale,notes,source_file,extraction_date
"How good or bad for humans will High-Level Machine Intelligence (HLMI) be? (Assume HLMI will exist. How positive or negative do you expect the overall impact of this to be on humanity, in the long run?)",AI_Sentiment,AI Impacts,Global,2023-10-01,52.0,21.0,27.0,2704.0,"Extremely good (e.g. rapid growth in human flourishing), On balance good, More or less neutral, On balance bad, Extremely bad (e.g. human extinction)",Results are mean probabilities for 2023. Agreement combines 'Extremely good' (27%) and 'On balance good' (25%). Neutral is 'More or less neutral' (21%). Disagreement combines 'On balance bad' (15%) and 'Extremely bad' (12%).,ai_impacts_oct_2023.pdf,2025-07-06
What probability do you put on future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species?,Extinction_Risk,AI Impacts,Global,2023-10-01,16.2,,,1321.0,Probability percentage,Mean probability. Median was 5%.,ai_impacts_oct_2023.pdf,2025-07-06
What probability do you put on human inability to control future advanced AI systems causing human extinction or similarly permanent and severe disempowerment of the human species?,Extinction_Risk,AI Impacts,Global,2023-10-01,19.4,,,661.0,Probability percentage,Mean probability. Median was 10%.,ai_impacts_oct_2023.pdf,2025-07-06
What probability do you put on future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species within the next 100 years?,Extinction_Risk,AI Impacts,Global,2023-10-01,14.4,,,655.0,Probability percentage,Mean probability. Median was 5%.,ai_impacts_oct_2023.pdf,2025-07-06
To what extent do you think people's concerns about future risks from AI are due to misunderstandings of AI research?,AI_Knowledge,AI Impacts,Global,2023-10-01,54.7,29.1,16.2,671.0,"Almost entirely, To a large extent, Somewhat, Not much, Hardly at all",Agreement combines 'Almost entirely' (10.7%) and 'To a large extent' (44%). Neutral is 'Somewhat' (29.1%). Disagreement combines 'Not much' (14.6%) and 'Hardly at all' (1.6%).,ai_impacts_oct_2023.pdf,2025-07-06
What rate of global AI progress over the next five years would make you feel most optimistic for humanity's future? (Assume any change in speed affects all projects equally.),AI_Sentiment,AI Impacts,Global,2023-10-01,38.4,26.9,34.7,,"Much slower, Somewhat slower, Current speed, Somewhat faster, Much faster",Agreement combines 'Somewhat faster' (22.8%) and 'Much faster' (15.6%). Neutral is 'Current speed' (26.9%). Disagreement combines 'Much slower' (4.8%) and 'Somewhat slower' (29.9%).,ai_impacts_oct_2023.pdf,2025-07-06
"How much should society prioritize AI safety research, relative to how much it is currently prioritized?",AI_Regulation,AI Impacts,Global,2023-10-01,70.0,22.0,8.0,1329.0,"Much less, Less, About the same, More, Much more",Agreement combines 'More' (36%) and 'Much more' (34%). Neutral is 'About the same' (22%). Disagreement combines 'Much less' (2%) and 'Less' (6%). Results are combined from two framings (with and without biased AI example).,ai_impacts_oct_2023.pdf,2025-07-06
"Do you think Stuart Russell's argument (that with advanced AI, 'you get exactly what you ask for, not what you want') points at an important problem?",AI_Risk_Concern,AI Impacts,Global,2023-10-01,54.0,32.0,14.0,,"Not a real problem, Not an important problem, Moderately important problem, Very important problem, Among the most important problems in the field",Agreement combines 'Very important problem' (41%) and 'Among the most important problems in the field' (13%). Neutral is 'Moderately important problem' (32%). Disagreement combines 'Not an important problem' (9%) and 'Not a real problem' (5%).,ai_impacts_oct_2023.pdf,2025-07-06
"How valuable is it to work on Stuart Russell's alignment problem today, compared to other problems in AI?",AI_Regulation,AI Impacts,Global,2023-10-01,31.0,39.0,30.0,,"Much less valuable, Less valuable, As valuable, More valuable, Much more valuable",Agreement combines 'More valuable' (22%) and 'Much more valuable' (9%). Neutral is 'As valuable' (39%). Disagreement combines 'Less valuable' (22%) and 'Much less valuable' (8%).,ai_impacts_oct_2023.pdf,2025-07-06
"How hard do you think Stuart Russell's alignment problem is, compared to other problems in AI?",Other,AI Impacts,Global,2023-10-01,57.0,30.0,13.0,,"Much easier, Easier, As hard, Harder, Much harder",Agreement combines 'Harder' (36%) and 'Much harder' (21%). Neutral is 'As hard' (30%). Disagreement combines 'Easier' (10%) and 'Much easier' (3%).,ai_impacts_oct_2023.pdf,2025-07-06
"For typical state-of-the-art AI systems in 2028, do you think it will be possible for users to know the true reasons for systems making a particular choice? (By “true reasons” we mean the AI correctly explains its internal decision-making process in a way humans can understand. By “true reasons” we do not mean the decision itself is correct.)",AI_Risk_Concern,AI Impacts,Global,2023-10-01,20.0,20.0,60.0,912.0,"Very unlikely (<10%), Unlikely (10-40%), Even odds (40-60%), Likely (60-90%), Very likely (>90%)",Agreement combines 'Likely' (15%) and 'Very likely' (5%). Neutral is 'Even odds' (20%). Disagreement combines 'Very unlikely' (25%) and 'Unlikely' (35%).,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Can talk like an expert human on most topics?,AI_Sentiment,AI Impacts,Global,2023-10-01,81.4,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Find unexpected ways to achieve goals?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,82.3,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Frequently behave in ways that are surprising to humans?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,69.1,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Can be 'jailbroken' to follow illegal commands?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Sometimes deceive humans to achieve a goal without this being intended by humans?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Have goals not aligned with human goals?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
"How likely is it that at least some AI systems in 2043 will have the trait: Are able to cause important actions in the world similarly to a human e.g. run a business, run an advocacy campaign?",AI_Sentiment,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Form collaborative relationships with other AI systems without this being intended by humans?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Make design improvements to increase their own performance?,AI_Sentiment,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Can be trusted to accurately explain their actions?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,55.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'.,ai_impacts_oct_2023.pdf,2025-07-06
How likely is it that at least some AI systems in 2043 will have the trait: Take actions to attain power?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,45.0,,,649.0,"very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",Percentage of respondents who answered 'likely' or 'very likely'. This trait had a median answer below 'even chance'.,ai_impacts_oct_2023.pdf,2025-07-06
"How concerning is the scenario: AI makes it easy to spread false information, e.g. deepfakes?",AI_Risk_Concern,AI Impacts,Global,2023-10-01,86.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: AI systems manipulate large-scale public opinion trends?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,79.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: Authoritarian rulers use AI to control their population?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,73.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: AI lets dangerous groups make powerful tools (e.g. engineered viruses)?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,73.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: AI systems worsen economic inequality by disproportionately benefiting certain individuals?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,71.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
"How concerning is the scenario: Bias in AI systems makes unjust situations worse, e.g. AI systems learn to discriminate by gender or race in hiring processes?",AI_Risk_Concern,AI Impacts,Global,2023-10-01,68.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
"How concerning is the scenario: A powerful AI system has its goals not set right, causing a catastrophe (e.g. it develops and uses powerful weapons)?",AI_Risk_Concern,AI Impacts,Global,2023-10-01,67.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: People interact with other humans less because they are spending more time interacting with AI systems?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,62.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: Near-full automation of labor leaves most people economically powerless?,Job_Displacement,AI Impacts,Global,2023-10-01,61.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: AI systems with the wrong goals become very powerful and reduce the role of humans in making decisions?,AI_Risk_Concern,AI Impacts,Global,2023-10-01,60.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
How concerning is the scenario: Near-full automation of labor makes people struggle to find meaning in their lives?,Job_Displacement,AI Impacts,Global,2023-10-01,55.0,,,1345.0,"no concern, a little concern, substantial concern, extreme concern",Agreement combines 'substantial concern' and 'extreme concern'.,ai_impacts_oct_2023.pdf,2025-07-06
"How likely do you find the argument to be broadly correct: If AI systems do nearly all research and development, improvements in AI will accelerate the pace of technological progress, including further progress in AI. Over a short period (less than 5 years), this feedback loop could cause technological progress to become more than an order of magnitude faster.",AI_Sentiment,AI Impacts,Global,2023-10-01,50.0,24.0,26.0,299.0,"Quite unlikely (0-20%), Unlikely (21-40%), About even chance (41-60%), Likely (61-80%), Quite likely (81-100%)",Agreement combines 'Likely' (26%) and 'Quite likely' (24%). Neutral is 'About even chance' (24%). Disagreement combines 'Unlikely' (17%) and 'Quite unlikely' (9%).,ai_impacts_oct_2023.pdf,2025-07-06
How much thought have you given in the past to when HLMI (or something similar) will be developed?,AI_Knowledge,AI Impacts,Global,2023-10-01,10.3,,,,"A great deal, A lot, Some, A little, Very little","Only 7.6% said 'A great deal'. The 10.3% figure is for 'A great deal' for social impacts, not HLMI timing. This question is not directly extractable as a binary/Likert scale with agreement/neutral/disagreement percentages from the provided text.",ai_impacts_oct_2023.pdf,2025-07-06
How much thought have you given in the past to social impacts of smarter-than-human machines?,AI_Knowledge,AI Impacts,Global,2023-10-01,10.3,,,,"A great deal, A lot, Some, A little, Very little",Only 10.3% said 'A great deal'. This question is not directly extractable as a binary/Likert scale with agreement/neutral/disagreement percentages from the provided text.,ai_impacts_oct_2023.pdf,2025-07-06
How much do you think that you disagreed with the typical AI researcher about when HLMI would exist?,AI_Knowledge,AI Impacts,Global,2023-10-01,10.0,46.0,44.0,671.0,"Not much, A moderate amount, A lot",Agreement is 'A lot' (10%). Neutral is 'A moderate amount' (46%). Disagreement is 'Not much' (44%).,ai_impacts_oct_2023.pdf,2025-07-06
