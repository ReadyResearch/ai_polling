[
  {
    "question_text": "How good or bad for humans will High-Level Machine Intelligence (HLMI) be? (Assume HLMI will exist. How positive or negative do you expect the overall impact of this to be on humanity, in the long run?)",
    "response_scale": "Extremely good (e.g. rapid growth in human flourishing), On balance good, More or less neutral, On balance bad, Extremely bad (e.g. human extinction)",
    "category": "AI_Sentiment",
    "agreement": 52.0,
    "neutral": 21.0,
    "disagreement": 27.0,
    "n_respondents": 2704,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Results are mean probabilities for 2023. Agreement combines 'Extremely good' (27%) and 'On balance good' (25%). Neutral is 'More or less neutral' (21%). Disagreement combines 'On balance bad' (15%) and 'Extremely bad' (12%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "What probability do you put on future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species?",
    "response_scale": "Probability percentage",
    "category": "Extinction_Risk",
    "agreement": 16.2,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1321,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Mean probability. Median was 5%.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "What probability do you put on human inability to control future advanced AI systems causing human extinction or similarly permanent and severe disempowerment of the human species?",
    "response_scale": "Probability percentage",
    "category": "Extinction_Risk",
    "agreement": 19.4,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 661,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Mean probability. Median was 10%.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "What probability do you put on future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species within the next 100 years?",
    "response_scale": "Probability percentage",
    "category": "Extinction_Risk",
    "agreement": 14.4,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 655,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Mean probability. Median was 5%.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "To what extent do you think people's concerns about future risks from AI are due to misunderstandings of AI research?",
    "response_scale": "Almost entirely, To a large extent, Somewhat, Not much, Hardly at all",
    "category": "AI_Knowledge",
    "agreement": 54.7,
    "neutral": 29.1,
    "disagreement": 16.2,
    "n_respondents": 671,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Almost entirely' (10.7%) and 'To a large extent' (44%). Neutral is 'Somewhat' (29.1%). Disagreement combines 'Not much' (14.6%) and 'Hardly at all' (1.6%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "What rate of global AI progress over the next five years would make you feel most optimistic for humanity's future? (Assume any change in speed affects all projects equally.)",
    "response_scale": "Much slower, Somewhat slower, Current speed, Somewhat faster, Much faster",
    "category": "AI_Sentiment",
    "agreement": 38.4,
    "neutral": 26.9,
    "disagreement": 34.7,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Somewhat faster' (22.8%) and 'Much faster' (15.6%). Neutral is 'Current speed' (26.9%). Disagreement combines 'Much slower' (4.8%) and 'Somewhat slower' (29.9%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How much should society prioritize AI safety research, relative to how much it is currently prioritized?",
    "response_scale": "Much less, Less, About the same, More, Much more",
    "category": "AI_Regulation",
    "agreement": 70.0,
    "neutral": 22.0,
    "disagreement": 8.0,
    "n_respondents": 1329,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'More' (36%) and 'Much more' (34%). Neutral is 'About the same' (22%). Disagreement combines 'Much less' (2%) and 'Less' (6%). Results are combined from two framings (with and without biased AI example).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "Do you think Stuart Russell's argument (that with advanced AI, 'you get exactly what you ask for, not what you want') points at an important problem?",
    "response_scale": "Not a real problem, Not an important problem, Moderately important problem, Very important problem, Among the most important problems in the field",
    "category": "AI_Risk_Concern",
    "agreement": 54.0,
    "neutral": 32.0,
    "disagreement": 14.0,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Very important problem' (41%) and 'Among the most important problems in the field' (13%). Neutral is 'Moderately important problem' (32%). Disagreement combines 'Not an important problem' (9%) and 'Not a real problem' (5%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How valuable is it to work on Stuart Russell's alignment problem today, compared to other problems in AI?",
    "response_scale": "Much less valuable, Less valuable, As valuable, More valuable, Much more valuable",
    "category": "AI_Regulation",
    "agreement": 31.0,
    "neutral": 39.0,
    "disagreement": 30.0,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'More valuable' (22%) and 'Much more valuable' (9%). Neutral is 'As valuable' (39%). Disagreement combines 'Less valuable' (22%) and 'Much less valuable' (8%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How hard do you think Stuart Russell's alignment problem is, compared to other problems in AI?",
    "response_scale": "Much easier, Easier, As hard, Harder, Much harder",
    "category": "Other",
    "agreement": 57.0,
    "neutral": 30.0,
    "disagreement": 13.0,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Harder' (36%) and 'Much harder' (21%). Neutral is 'As hard' (30%). Disagreement combines 'Easier' (10%) and 'Much easier' (3%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "For typical state-of-the-art AI systems in 2028, do you think it will be possible for users to know the true reasons for systems making a particular choice? (By “true reasons” we mean the AI correctly explains its internal decision-making process in a way humans can understand. By “true reasons” we do not mean the decision itself is correct.)",
    "response_scale": "Very unlikely (<10%), Unlikely (10-40%), Even odds (40-60%), Likely (60-90%), Very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 20.0,
    "neutral": 20.0,
    "disagreement": 60.0,
    "n_respondents": 912,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Likely' (15%) and 'Very likely' (5%). Neutral is 'Even odds' (20%). Disagreement combines 'Very unlikely' (25%) and 'Unlikely' (35%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Can talk like an expert human on most topics?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Sentiment",
    "agreement": 81.4,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Find unexpected ways to achieve goals?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 82.3,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Frequently behave in ways that are surprising to humans?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 69.1,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Can be 'jailbroken' to follow illegal commands?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Sometimes deceive humans to achieve a goal without this being intended by humans?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Have goals not aligned with human goals?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Are able to cause important actions in the world similarly to a human e.g. run a business, run an advocacy campaign?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Sentiment",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Form collaborative relationships with other AI systems without this being intended by humans?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Make design improvements to increase their own performance?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Sentiment",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Can be trusted to accurately explain their actions?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely is it that at least some AI systems in 2043 will have the trait: Take actions to attain power?",
    "response_scale": "very unlikely (<10%), unlikely (10-40%), even chance (40-60%), likely (60-90%), very likely (>90%)",
    "category": "AI_Risk_Concern",
    "agreement": 45.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 649,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Percentage of respondents who answered 'likely' or 'very likely'. This trait had a median answer below 'even chance'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: AI makes it easy to spread false information, e.g. deepfakes?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 86.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: AI systems manipulate large-scale public opinion trends?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 79.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: Authoritarian rulers use AI to control their population?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 73.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: AI lets dangerous groups make powerful tools (e.g. engineered viruses)?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 73.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: AI systems worsen economic inequality by disproportionately benefiting certain individuals?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 71.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: Bias in AI systems makes unjust situations worse, e.g. AI systems learn to discriminate by gender or race in hiring processes?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 68.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: A powerful AI system has its goals not set right, causing a catastrophe (e.g. it develops and uses powerful weapons)?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 67.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: People interact with other humans less because they are spending more time interacting with AI systems?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 62.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: Near-full automation of labor leaves most people economically powerless?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "Job_Displacement",
    "agreement": 61.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: AI systems with the wrong goals become very powerful and reduce the role of humans in making decisions?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "AI_Risk_Concern",
    "agreement": 60.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How concerning is the scenario: Near-full automation of labor makes people struggle to find meaning in their lives?",
    "response_scale": "no concern, a little concern, substantial concern, extreme concern",
    "category": "Job_Displacement",
    "agreement": 55.0,
    "neutral": null,
    "disagreement": null,
    "n_respondents": 1345,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'substantial concern' and 'extreme concern'.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How likely do you find the argument to be broadly correct: If AI systems do nearly all research and development, improvements in AI will accelerate the pace of technological progress, including further progress in AI. Over a short period (less than 5 years), this feedback loop could cause technological progress to become more than an order of magnitude faster.",
    "response_scale": "Quite unlikely (0-20%), Unlikely (21-40%), About even chance (41-60%), Likely (61-80%), Quite likely (81-100%)",
    "category": "AI_Sentiment",
    "agreement": 50.0,
    "neutral": 24.0,
    "disagreement": 26.0,
    "n_respondents": 299,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement combines 'Likely' (26%) and 'Quite likely' (24%). Neutral is 'About even chance' (24%). Disagreement combines 'Unlikely' (17%) and 'Quite unlikely' (9%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How much thought have you given in the past to when HLMI (or something similar) will be developed?",
    "response_scale": "A great deal, A lot, Some, A little, Very little",
    "category": "AI_Knowledge",
    "agreement": 10.3,
    "neutral": null,
    "disagreement": null,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Only 7.6% said 'A great deal'. The 10.3% figure is for 'A great deal' for social impacts, not HLMI timing. This question is not directly extractable as a binary/Likert scale with agreement/neutral/disagreement percentages from the provided text.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How much thought have you given in the past to social impacts of smarter-than-human machines?",
    "response_scale": "A great deal, A lot, Some, A little, Very little",
    "category": "AI_Knowledge",
    "agreement": 10.3,
    "neutral": null,
    "disagreement": null,
    "n_respondents": null,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Only 10.3% said 'A great deal'. This question is not directly extractable as a binary/Likert scale with agreement/neutral/disagreement percentages from the provided text.",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  },
  {
    "question_text": "How much do you think that you disagreed with the typical AI researcher about when HLMI would exist?",
    "response_scale": "Not much, A moderate amount, A lot",
    "category": "AI_Knowledge",
    "agreement": 10.0,
    "neutral": 46.0,
    "disagreement": 44.0,
    "n_respondents": 671,
    "country": "Global",
    "survey_organisation": "AI Impacts",
    "fieldwork_date": "2023-10-01",
    "notes": "Agreement is 'A lot' (10%). Neutral is 'A moderate amount' (46%). Disagreement is 'Not much' (44%).",
    "extraction_date": "2025-07-06 20:20:27",
    "source_file": "ai_impacts_oct_2023.pdf"
  }
]